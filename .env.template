# AI Creativity Benchmark Onboarding System
# Copy this file to .env and fill in your API keys

# =============================================================================
# Required for Onboarding
# =============================================================================

# OpenRouter API key (provides access to multiple models)
# Get one at: https://openrouter.ai/
OPENROUTER_API_KEY=sk-or-...

# =============================================================================
# Required for Pipeline Scripts (01-05)
# =============================================================================

# OpenAI API key (for paper screening with GPT-4)
# Get one at: https://platform.openai.com/
OPENAI_API_KEY=sk-...

# Google API key (for Gemini models - verification, PDF download, extraction)
# Get one at: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=...

# =============================================================================
# Optional
# =============================================================================

# HuggingFace token (for private datasets)
# Get one at: https://huggingface.co/settings/tokens
HF_TOKEN=hf_...

# GitHub token (for private repos, higher rate limits)
# Get one at: https://github.com/settings/tokens
GITHUB_TOKEN=ghp_...

# Anthropic API key (if using Claude directly instead of via OpenRouter)
ANTHROPIC_API_KEY=sk-ant-...

# =============================================================================
# Model Configuration (defaults shown)
# =============================================================================

# Model for structured extraction tasks
EXTRACTION_MODEL=google/gemini-3-flash-preview

# Cheap model for pilot testing
PILOT_MODEL=google/gemini-2.0-flash-lite-001

# Model for LLM-as-judge evaluation
JUDGE_MODEL=anthropic/claude-sonnet-4

# Model for implementation review
REVIEW_MODEL=anthropic/claude-sonnet-4

# =============================================================================
# Validation Thresholds (defaults shown)
# =============================================================================

# Minimum dataset rows required
MIN_DATASET_SIZE=50

# Minimum confidence for semantic match
SEMANTIC_CONFIDENCE_THRESHOLD=0.7

# Number of instances for pilot test
PILOT_INSTANCES=5

# Max self-correction attempts
MAX_CORRECTION_ATTEMPTS=3
